Got it — Physical means you want to count replicas too (actual disk consumed across all replicas/hosts). Below is the prod-ready doc + final query packs aligned to that.


---

Production Implementation Doc — Physical Table Storage Trending

Goal

Capture physical disk usage per table across the whole cluster over time, so you can:

See trend (hour/day/week)

Find top growers

Detect parts explosion

Correlate disk pressure with table growth


Physical = uses clusterAllReplicas() so replicas are included.


---

1) Create monitoring database (cluster-wide)

CREATE DATABASE IF NOT EXISTS monitoring ON CLUSTER '{CLUSTER}';


---

2) Create tables (cluster-wide)

2.1 Cluster physical storage history (recommended baseline)

CREATE TABLE IF NOT EXISTS monitoring.table_storage_history_physical
ON CLUSTER '{CLUSTER}'
(
    ts DateTime CODEC(Delta, ZSTD(3)),
    database LowCardinality(String),
    table LowCardinality(String),

    bytes_on_disk UInt64 CODEC(Delta, ZSTD(3)),
    rows UInt64 CODEC(Delta, ZSTD(3)),
    active_parts UInt32 CODEC(Delta, ZSTD(3)),

    compressed_bytes UInt64 CODEC(Delta, ZSTD(3)),
    uncompressed_bytes UInt64 CODEC(Delta, ZSTD(3)),
    compression_ratio Float32 CODEC(ZSTD(3))
)
ENGINE = MergeTree
PARTITION BY toYYYYMM(ts)
ORDER BY (database, table, ts);

2.2 Optional: per-host physical storage history (for imbalance debugging)

CREATE TABLE IF NOT EXISTS monitoring.table_storage_history_physical_host
ON CLUSTER '{CLUSTER}'
(
    ts DateTime CODEC(Delta, ZSTD(3)),
    host LowCardinality(String),
    disk LowCardinality(String),

    database LowCardinality(String),
    table LowCardinality(String),

    bytes_on_disk UInt64 CODEC(Delta, ZSTD(3)),
    rows UInt64 CODEC(Delta, ZSTD(3)),
    active_parts UInt32 CODEC(Delta, ZSTD(3))
)
ENGINE = MergeTree
PARTITION BY toYYYYMM(ts)
ORDER BY (host, database, table, ts);


---

3) Retention (TTL)

Keep 180 days for cluster trend

ALTER TABLE monitoring.table_storage_history_physical
ON CLUSTER '{CLUSTER}'
MODIFY TTL ts + INTERVAL 180 DAY;

Keep 30–60 days for host-level (optional)

ALTER TABLE monitoring.table_storage_history_physical_host
ON CLUSTER '{CLUSTER}'
MODIFY TTL ts + INTERVAL 60 DAY;


---

4) Snapshot collector queries (Physical)

4.1 Insert cluster physical snapshot (run from ONE node)

Use bucketed time to reduce duplicates:

INSERT INTO monitoring.table_storage_history_physical
SELECT
    toStartOfMinute(now()) AS ts,
    database,
    table,
    sum(bytes_on_disk) AS bytes_on_disk,
    sum(rows) AS rows,
    count() AS active_parts,
    sum(data_compressed_bytes) AS compressed_bytes,
    sum(data_uncompressed_bytes) AS uncompressed_bytes,
    if(sum(data_compressed_bytes)=0, 0,
       sum(data_uncompressed_bytes) / sum(data_compressed_bytes)) AS compression_ratio
FROM clusterAllReplicas('{CLUSTER}', system.parts)
WHERE active
  AND database NOT IN ('system','information_schema','INFORMATION_SCHEMA')
GROUP BY database, table;

4.2 Insert host-level physical snapshot (optional)

INSERT INTO monitoring.table_storage_history_physical_host
SELECT
    toStartOfMinute(now()) AS ts,
    hostName() AS host,
    disk_name AS disk,
    database,
    table,
    sum(bytes_on_disk) AS bytes_on_disk,
    sum(rows) AS rows,
    count() AS active_parts
FROM clusterAllReplicas('{CLUSTER}', system.parts)
WHERE active
  AND database NOT IN ('system','information_schema','INFORMATION_SCHEMA')
GROUP BY host, disk, database, table;


---

5) Scheduling (prod)

Option A: systemd timer (recommended)

Run every 10 minutes, with retry via systemd.

/etc/systemd/system/ch-storage-snapshot.service

[Unit]
Description=ClickHouse physical table storage snapshot

[Service]
Type=oneshot
User=clickhouse
ExecStart=/usr/bin/clickhouse-client --host 127.0.0.1 --multiquery --query "INSERT INTO monitoring.table_storage_history_physical SELECT toStartOfMinute(now()) AS ts, database, table, sum(bytes_on_disk), sum(rows), count(), sum(data_compressed_bytes), sum(data_uncompressed_bytes), if(sum(data_compressed_bytes)=0,0,sum(data_uncompressed_bytes)/sum(data_compressed_bytes)) FROM clusterAllReplicas('{CLUSTER}', system.parts) WHERE active AND database NOT IN ('system','information_schema','INFORMATION_SCHEMA') GROUP BY database, table;"

/etc/systemd/system/ch-storage-snapshot.timer

[Unit]
Description=Run ClickHouse storage snapshot every 10 minutes

[Timer]
OnBootSec=2min
OnUnitActiveSec=10min
Persistent=true

[Install]
WantedBy=timers.target

Enable:

sudo systemctl daemon-reload
sudo systemctl enable --now ch-storage-snapshot.timer
systemctl list-timers | grep ch-storage-snapshot

Option B: cron

Works, but less robust than systemd timers.


---

6) Permissions (prod hygiene)

Create a limited user, example:

CREATE USER IF NOT EXISTS monitoring_writer IDENTIFIED WITH sha256_password BY 'STRONG_PASS';
GRANT INSERT, SELECT ON monitoring.* TO monitoring_writer;
GRANT SELECT ON system.parts TO monitoring_writer;

(If you use the host-level collector: also grant select on system.parts and you’re fine.)


---

Queries Pack — “Table Stats” (Current physical, across hosts)

1) Current physical size per table (cluster)

SELECT
  database,
  table,
  formatReadableSize(sum(bytes_on_disk)) AS physical_size,
  sum(rows) AS rows,
  count() AS active_parts,
  round(sum(data_uncompressed_bytes) / NULLIF(sum(data_compressed_bytes),0), 2) AS compression_ratio
FROM clusterAllReplicas('{CLUSTER}', system.parts)
WHERE active
  AND database NOT IN ('system','information_schema','INFORMATION_SCHEMA')
GROUP BY database, table
ORDER BY sum(bytes_on_disk) DESC
LIMIT 200;

2) Current physical size by database (cluster)

SELECT
  database,
  formatReadableSize(sum(bytes_on_disk)) AS physical_db_size,
  sum(rows) AS rows
FROM clusterAllReplicas('{CLUSTER}', system.parts)
WHERE active
  AND database NOT IN ('system','information_schema','INFORMATION_SCHEMA')
GROUP BY database
ORDER BY sum(bytes_on_disk) DESC;

3) Biggest partitions (physical, cluster)

SELECT
  database,
  table,
  partition,
  formatReadableSize(sum(bytes_on_disk)) AS partition_size,
  sum(rows) AS rows,
  count() AS parts
FROM clusterAllReplicas('{CLUSTER}', system.parts)
WHERE active
  AND database NOT IN ('system','information_schema','INFORMATION_SCHEMA')
GROUP BY database, table, partition
ORDER BY sum(bytes_on_disk) DESC
LIMIT 200;

4) Tables with parts explosion (merge risk)

SELECT
  database,
  table,
  count() AS active_parts,
  formatReadableSize(sum(bytes_on_disk)) AS size
FROM clusterAllReplicas('{CLUSTER}', system.parts)
WHERE active
GROUP BY database, table
HAVING active_parts > 500
ORDER BY active_parts DESC;

5) Disk usage per host (physical disk pressure)

SELECT
    hostName() AS host,
    name AS disk,
    formatReadableSize(total_space) AS total,
    formatReadableSize(free_space) AS free,
    round((total_space - free_space) / total_space * 100, 2) AS used_pct
FROM clusterAllReplicas('{CLUSTER}', system.disks)
ORDER BY used_pct DESC, host, disk;


---

Queries Pack — Trend (from monitoring DB)

6) Verify ingestion (last 20 rows)

SELECT *
FROM monitoring.table_storage_history_physical
ORDER BY ts DESC
LIMIT 20;

7) Trend for one table (hourly, last 7d)

SELECT
  toStartOfHour(ts) AS hour,
  formatReadableSize(avg(bytes_on_disk)) AS avg_physical_size
FROM monitoring.table_storage_history_physical
WHERE database = 'YOUR_DB'
  AND table = 'YOUR_TABLE'
  AND ts >= now() - INTERVAL 7 DAY
GROUP BY hour
ORDER BY hour;

8) Top growers in last 24h (physical)

WITH
latest AS (SELECT max(ts) AS t1 FROM monitoring.table_storage_history_physical),
prev AS (
  SELECT max(ts) AS t0
  FROM monitoring.table_storage_history_physical
  WHERE ts <= (SELECT t1 FROM latest) - INTERVAL 24 HOUR
)
SELECT
  cur.database,
  cur.table,
  formatReadableSize(cur.bytes) AS size_now,
  formatReadableSize(prev.bytes) AS size_24h_ago,
  formatReadableSize(cur.bytes - prev.bytes) AS growth_24h,
  round((cur.bytes - prev.bytes) / NULLIF(prev.bytes, 0) * 100, 2) AS growth_pct
FROM
(
  SELECT database, table, bytes_on_disk AS bytes
  FROM monitoring.table_storage_history_physical
  WHERE ts = (SELECT t1 FROM latest)
) cur
LEFT JOIN
(
  SELECT database, table, bytes_on_disk AS bytes
  FROM monitoring.table_storage_history_physical
  WHERE ts = (SELECT t0 FROM prev)
) prev
ON cur.database = prev.database AND cur.table = prev.table
ORDER BY (cur.bytes - coalesce(prev.bytes, 0)) DESC
LIMIT 100;

9) Daily sizes for top 20 tables (last 30d)

WITH top AS
(
  SELECT database, table
  FROM monitoring.table_storage_history_physical
  WHERE ts >= now() - INTERVAL 1 DAY
  GROUP BY database, table
  ORDER BY max(bytes_on_disk) DESC
  LIMIT 20
)
SELECT
  toDate(ts) AS day,
  h.database,
  h.table,
  formatReadableSize(avg(h.bytes_on_disk)) AS avg_size
FROM monitoring.table_storage_history_physical h
INNER JOIN top USING (database, table)
WHERE ts >= now() - INTERVAL 30 DAY
GROUP BY day, database, table
ORDER BY day, avg(h.bytes_on_disk) DESC;


---

One critical note (so you don’t get surprised)

Because you chose Physical, the “size” will be roughly:

2× if you have 2 replicas (plus overhead), compared to “logical” size.


That’s correct and intended.


---

If you paste your cluster name from:

SELECT DISTINCT cluster FROM system.clusters;

…I’ll rewrite every query with your exact cluster name and also give you a “single command” installer script (all CREATE + TTL + systemd timer).